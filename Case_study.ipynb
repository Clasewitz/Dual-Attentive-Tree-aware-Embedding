{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customs Frauds Detection with Python\n",
    "\n",
    "## BACUDA Series\n",
    "## How to use DATE for interpretate results\n",
    "\n",
    "### Yu-Che Tsai (roytsai27 @gmail.com), Department of Statistics, National Cheng Kung University\n",
    "\n",
    "## Short Summary\n",
    "> DATE first takes a set of leaf-node from the pre-trained XGBoost classifier as input. <br>\n",
    "It then applies attention mechanism by incorporating the use embedding and HS6 code embedding. <br>\n",
    "The attention mechanism was used to dynamically assign weights to each leaf-node(i.e. cross-features), leaf-nodes with a higher weights means it contribute more to our prediction results.<br>\n",
    "After we trained DATE on a specific dataset, we could feed unseen data and observe the attention distribution to find out which cross-feature contribute more to our prediction.\n",
    "\n",
    "## Requirements\n",
    "* A trained XGBoost classifer, which should be saved aftering training (should be a .txt file).\n",
    "* A trained DATE model, saved with .pkl file.\n",
    "* leaf_index.pickle to be used for projecting leaf-index to tree structure.\n",
    "* Dataset to analysis, could be either training data or test data.\n",
    "\n",
    "## Dataset\n",
    "* The transaction level from Nigera dataset from 2013~2017\n",
    "* Since we have already trained DATE with a set of training data(i.e. 2013 to 2016), we only anaylze the testing set in this notebook.\n",
    "\n",
    "\n",
    "## Guideline\n",
    "1. Load the pre-trained XGBoost Classifier to obtain the leaf-node(cross features).<br>\n",
    "2. Load the trained DATE model\n",
    "3. Convert the dataset into torch tensors \n",
    "4. Use DATE(data) to get prediction outputs\n",
    "4. Since Neural Networks in pytorch are store in python **class** format, we could obtain attention weight by calling \"model.attention_w\" attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed dataset\n",
    "with open(\"./processed_data.pickle\",\"rb\") as f:\n",
    "    processed = pickle.load(f)\n",
    "test = processed[\"raw\"][\"test\"]\n",
    "test = test.reset_index(drop=True) # raw data(test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DATE model and testing set with torch format\n",
    "Note that the torch_data.pickle file was created by generate_loader.py. <br>\n",
    "Since DATE is implemented pytorch, the input data for DATE should be converted into **torch.tensor**. <br>\n",
    "We use \"dataloader\" in torch to split test data into small batches to avoid memory error(out of memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DATE model\n",
    "model = torch.load(\"./saved_models/DATE_0.7467.pkl\").module\n",
    "\n",
    "# load torch dataset \n",
    "with open(\"../torch_data.pickle\",\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "test_dataset = data[\"test_dataset\"]\n",
    "\n",
    "# create dataloader\n",
    "batch_size = 256 # the data size per batch\n",
    "test_loader = Data.DataLoader( # Note that you could iterate dataloader with for loop to obtain batches\n",
    "    dataset=test_dataset,     \n",
    "    batch_size=batch_size,      \n",
    "    shuffle=False,               \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain attention weights for each transaction\n",
    "Each transaction is given as the input for XGBoost model and output the **index** of leaf-nodes.<br>\n",
    "Therfore, if the XGBoost is built with N trees, there would be a list of N index from XGBoost.<br>\n",
    "Based on previous results, DATE further learns attentive weights for each leaf-node(cross-feature).<br>\n",
    "Therefore, there would be N attentive weights given a single transaction with it's corresponding leaf-nodes. Note that the summation of weights is equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weight = [] # create a list to store attention weights for each transaction\n",
    "predicted_illicit_prob = []\n",
    "predicted_rev = []\n",
    "device = model.device # the device id of model and data should be consistant\n",
    "\n",
    "# iterate over test data\n",
    "for batch_feature,batch_user,batch_item,batch_cls,batch_reg in test_loader:\n",
    "    model.eval() # this line is to set the model for evaluation stage by stoping some parameters(e.g. dropout)\n",
    "    \n",
    "    # convert the data into same device as our model \n",
    "    batch_feature,batch_user,batch_item,batch_cls,batch_reg =  \\\n",
    "    batch_feature.to(device), batch_user.to(device), batch_item.to(device),\\\n",
    "     batch_cls.to(device), batch_reg.to(device)\n",
    "    batch_cls,batch_reg = batch_cls.view(-1,1), batch_reg.view(-1,1)\n",
    "\n",
    "    # model output\n",
    "    classification_output, regression_output, hidden_vector = model(batch_feature,batch_user,batch_item) # get the prediction output\n",
    "    \n",
    "    # convert torch.tensor to numpy array\n",
    "    classification_output = classification_output.detach().cpu().numpy()\n",
    "    regression_output = regression_output.detach().cpu().numpy()\n",
    "    att_w = model.attention_w.detach().cpu().numpy()\n",
    "    att_w = att_w.reshape(-1,100)\n",
    "    \n",
    "    attention_weight.extend(att_w.tolist())\n",
    "    predicted_illicit_prob.extend(classification_output.ravel().tolist())\n",
    "    predicted_rev.extend(regression_output.ravel().tolist())\n",
    "\n",
    "# conver python list to numpy array\n",
    "attention_weight = np.array(attention_weight)\n",
    "predicted_illicit_prob = np.array(predicted_illicit_prob)\n",
    "predicted_rev = np.array(predicted_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Averaged attention weight visualization\n",
    "After obtaining attention weights among all of the test set, we could average the weights and observe the distribution of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(100),attention_weight.mean(axis=0))\n",
    "plt.xlabel(\"Leaf node\")\n",
    "plt.ylabel(\"Weights\")\n",
    "plt.title(\"The averaged attentive weights among all transactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample transactions\n",
    "Due to the great amount of transactions, we sample 1 licit and 1 illicit transaction for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of sampled data: 118239\n"
     ]
    }
   ],
   "source": [
    "number_sampled = 1\n",
    "illicit_sample = test[test.illicit==1].sample(number_sampled,random_state=1) # sample from illicit samples\n",
    "transaction_id = illicit_sample.index[0] # get the index of sampled data\n",
    "print(\"Index of sampled data:\",transaction_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>OFFICE</th>\n",
       "      <th>SGD.NUMBER</th>\n",
       "      <th>SGD.DATE</th>\n",
       "      <th>RECEIPT.NUMBER</th>\n",
       "      <th>RECEIPT.DATE</th>\n",
       "      <th>IMPORTER.TIN</th>\n",
       "      <th>DECLARANT.CODE</th>\n",
       "      <th>FOB.VALUE</th>\n",
       "      <th>CIF.VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>RiskH.TARIFF.DESCRIPTION</th>\n",
       "      <th>RiskH.TARIFF.CODE</th>\n",
       "      <th>RiskH.QUANTITY</th>\n",
       "      <th>RiskH.HS6</th>\n",
       "      <th>RiskH.HS4</th>\n",
       "      <th>RiskH.HS2</th>\n",
       "      <th>RiskH.OFFICE</th>\n",
       "      <th>RiskH.OFFICE&amp;IMPORTER.TIN</th>\n",
       "      <th>RiskH.OFFICE&amp;HS6</th>\n",
       "      <th>RiskH.OFFICE&amp;ISO3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118239</th>\n",
       "      <td>2017</td>\n",
       "      <td>OFFICE91</td>\n",
       "      <td>SGD922876</td>\n",
       "      <td>17-11-28</td>\n",
       "      <td>RCP916239</td>\n",
       "      <td>17-12-04</td>\n",
       "      <td>IMP600519</td>\n",
       "      <td>DEC685844</td>\n",
       "      <td>7033400.0</td>\n",
       "      <td>8335191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR    OFFICE SGD.NUMBER  SGD.DATE RECEIPT.NUMBER RECEIPT.DATE  \\\n",
       "118239  2017  OFFICE91  SGD922876  17-11-28      RCP916239     17-12-04   \n",
       "\n",
       "       IMPORTER.TIN DECLARANT.CODE  FOB.VALUE  CIF.VALUE  ...  \\\n",
       "118239    IMP600519      DEC685844  7033400.0  8335191.0  ...   \n",
       "\n",
       "        RiskH.TARIFF.DESCRIPTION RiskH.TARIFF.CODE  RiskH.QUANTITY  RiskH.HS6  \\\n",
       "118239                         0                 0               0          0   \n",
       "\n",
       "        RiskH.HS4 RiskH.HS2 RiskH.OFFICE  RiskH.OFFICE&IMPORTER.TIN  \\\n",
       "118239          0         0            0                          1   \n",
       "\n",
       "        RiskH.OFFICE&HS6  RiskH.OFFICE&ISO3  \n",
       "118239                 0                  0  \n",
       "\n",
       "[1 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "illicit_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the inspection information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the inspection information of sampled data\n",
      "----------------------------------------------------\n",
      "1.PLS REFER SAD TO SDV VALUATION AFTER EXAMINATION.\r",
      "\r\n",
      "ALERT!!! PLS REFER SGD TO CPC BEFORE RELEASE, WRONG \r",
      "\r\n",
      "CLASSIFICATION SUSPECTED. SYSTEM AUDIT\r",
      "\r\n",
      "2.01X40FT CONT.NO:FSCU9742993,OPENED,EXMD BY 36158 DSC ADEMOLA,W.J & 49812 ASC1 DADA,B.O & FTC:\r",
      "\r\n",
      "250 BALES OF JUTE FIBRE(FILTERS).\r",
      "\r\n",
      "Q&A CPC REFER PLS.\r",
      "\r\n",
      "SDV VALUATION REFERS.\r",
      "\r\n",
      "3.ALERT!!!  BASED ON HQ ALERT OF 29/11/2017, THIS DECLARATION HAS BEEN ALERTED BY SYSTEM AUDIT AS UNDERVALUE, PLEASE REFER SGD TO VALUATION BEFORE RELEASE. (T&T, HQ).\r",
      "\r\n",
      "ADDITIONAL D/N OF =N=219,646 RAISED.\r",
      "\r\n",
      "\r",
      "\r\n",
      "4.D/N CONFIRMED PAID VID DIAMOND REF NO;063041220017012312\r",
      "\r\n",
      "\r",
      "\r\n",
      "5.C/EXAMINER,BASED ON EXAMINATION REPORT & MINUTE 4 ABOVE,YOU MAY PROCEED IF SATISFIED Q&A\r",
      "\r\n",
      "BASED ON THE REPORT ABOVE AND DN PAID.RELEASE AUTHORIZED BY 39268\r",
      "\r\n",
      "AC AGHOLOR A.I\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking the inspection information of sampled data\")\n",
    "print(\"-\"*52)\n",
    "for text in illicit_sample['INSPECTION.INFORMATION'].values:\n",
    "    print(text.strip())\n",
    "    print(\"-\"*52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze attention weight with XGBoost leaf-nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load leaf_index dictionary to project lead-id into XGBoost tree structure\n",
    "with open(\"leaf_index.pickle\",\"rb\") as f:\n",
    "    leaf_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probability:0.9994\n",
      "Trees with the highest attention weights: [98 32 13 12 28]\n",
      "The corresponding index of the leaf node: [1548, 504, 195, 179, 440]\n",
      "The node id in the original XGBoost model: [{98: 20}, {32: 30}, {13: 25}, {12: 23}, {28: 30}]\n"
     ]
    }
   ],
   "source": [
    "# first, take a look at the prediction probability of the transaction\n",
    "print(\"Prediction probability:%.4f\" % predicted_illicit_prob[transaction_id])\n",
    "top_k = 5 # number of cross feature to observe (select top k)\n",
    "test_leaves = test_dataset.tensors[0].numpy() # the leaf index for all transactions\n",
    "tree_id = np.argsort(attention_weight[transaction_id])[-top_k:] # obtain which trees have the hightest weights\n",
    "print(\"Trees with the highest attention weights:\",tree_id)\n",
    "leaf_id = [test_leaves[transaction_id][i] for i in tree_id] # obtain the leaf-id for the trees\n",
    "print(\"The corresponding index of the leaf node:\",leaf_id)\n",
    "\n",
    "# transform the leaf index to the original XGBoost tree structure\n",
    "# Variable leaf_index is a dictionary with {leaf-id: {tree-id,node-id}}\n",
    "xgb_cross_feature = [leaf_index[l] for l in leaf_id] \n",
    "print(\"The node id in the original XGBoost model:\",xgb_cross_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booster[0]:\n",
      "0:[TaxRatio<0.00182044168] yes=1,no=2,missing=1\n",
      "\t1:[TaxUnitquantity<22.8490429] yes=3,no=4,missing=3\n",
      "\t\t3:[TOTAL.TAXES<6823.5] yes=7,no=8,missing=7\n",
      "\t\t\t7:leaf=0.199860305\n",
      "\t\t\t8:leaf=0.0500000007\n",
      "\t\t4:[RiskH.OFFICE&IMPORTER.TIN<0.5] yes=9,no=10,missing=9\n",
      "\t\t\t9:[EXCHANGERATE<170.26001] yes=15,no=16,missing=15\n",
      "\t\t\t\t15:leaf=-0.162500009\n",
      "\t\t\t\t16:leaf=-0\n",
      "\t\t\t10:[GROSS.WEIGHT<34460] yes=17,no=18,missing=17\n",
      "\t\t\t\t17:leaf=0.150000006\n",
      "\t\t\t\t18:leaf=-0\n",
      "\t2:[RiskH.OFFICE&IMPORTER.TIN<0.5] yes=5,no=6,missing=5\n",
      "\t\t5:[CIF.VALUE<700005.5] yes=11,no=12,missing=11\n",
      "\t\t\t11:[RiskH.OFFICE&HS6<0.5] yes=19,no=20,missing=19\n",
      "\t\t\t\t19:leaf=-0.199470758\n",
      "\t\t\t\t20:leaf=-0.184831649\n",
      "\t\t\t12:[TaxRatio<0.437450051] yes=21,no=22,missing=21\n",
      "\t\t\t\t21:leaf=-0.195282146\n",
      "\t\t\t\t22:leaf=-0.198604077\n",
      "\t\t6:[RiskH.HS6.Origin<0.5] yes=13,no=14,missing=13\n",
      "\t\t\t13:[FOBCIFRatio<0.999917626] yes=23,no=24,missing=23\n",
      "\t\t\t\t23:leaf=-0.171607345\n",
      "\t\t\t\t24:leaf=-0.119938411\n",
      "\t\t\t14:[TaxRatio<0.280007631] yes=25,no=26,missing=25\n",
      "\t\t\t\t25:leaf=-0.0613040626\n",
      "\t\t\t\t26:leaf=-0.1579305\n"
     ]
    }
   ],
   "source": [
    "# read the contents of the file\n",
    "with open('xgb_model2.txt', 'r') as f:\n",
    "    txt_model = f.read()\n",
    "\n",
    "# Note: To maintain the clearness, only print the result for the first tree. Please print the whole text data when analyzing by yourself\n",
    "print(txt_model[:1015]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract dicision path\n",
    "From the previous cell, we could see that the tree structure is revealed. \"**booster[id]**\" denotes the tree id and follows with it's node id of each leaf-node.<br>\n",
    "We have already obtain the leaf-node and their tree-id is [{98: 20}, {32: 30}, {13: 25}, {12: 23}, {28: 30}].<br>\n",
    "Therefore, we would have decision paths for each leaf-node regrarding to the text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction probability:0.9994<br>\n",
    "Trees with the highest attention weights: [98 32 13 12 28]<br>\n",
    "The corresponding index of the leaf node: [1548, 504, 195, 179, 440]<br>\n",
    "The node id in the original XGBoost model: [{98: 20}, {32: 30}, {13: 25}, {12: 23}, {28: 30}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Paths\n",
    "* Leaf_id: 1548, Tree id: 98, Node id: 20 <br>\n",
    "path: [20<-9<-4<-1<-0] <br>\n",
    "cross feature: RiskH.OFFICE&IMPORTER.TIN>0.5 | TaxRatio<0.111423187 | TaxRatio>0.0686226115 | RiskH.QUANTITY<0.5\n",
    "* Leaf_id: 504, Tree id: 32, Node id:30 <br>\n",
    "path: [30<-14<-6<-2<-0] <br>\n",
    "cross feature: GROSS.WEIGHT>6047.4502 | SGD.DayofYear>460.5 | TaxRatio>0.00499979965 |RiskH.OFFICE&IMPORTER.TIN>0.5\n",
    "* Leaf_id: 195, Tree id: 13, Node id:25 <br>\n",
    "path: [25<-12<-5<-2<-0] <br>\n",
    "cross feature: FOBCIFRatio<0.999917626 | TaxRatio<0.0634894818 | RiskH.HS6.Origin<0.5 | RiskH.OFFICE&IMPORTER.TIN>0.5\n",
    "* Leaf_id: 179, Tree id: 12, Node id:23 <br>\n",
    "path: [23<-12<-5<-2<-0] <br>\n",
    "cross feature: FOBCIFRatio<0.999916792 | RiskH.IMPORTER.TIN>0.5 | RiskH.OFFICE&HS6<0.5 | RiskH.OFFICE&IMPORTER.TIN>0.5\n",
    "* Leaf_id: 440, Tree id: 28, Node id:30 <br>\n",
    "path: [30<-14<-6<-2<-0] <br>\n",
    "cross feature: TARIFF.CODE>2.50100147e+09 | TOTAL.TAXES>20007 | RiskH.DECLARANT.CODE>0.5 | RiskH.OFFICE&IMPORTER.TIN>0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
